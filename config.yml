# Note to dev:
# The following list is of configuration parameters is simply an example list of common parameters.
# Be sure to update the readme as you add and remove parameters to this file

# PREPROCESS encompasses all pieces that download, mask (remove artifacts) and perform transformations to convert the videos
# into "miniclips", which are stored locally as .npz (compressed numpy arrays) files. These will later be fed into the model
# (after performing other possible transformations, such as M Mode, which is currently the most effective).
PREPROCESS:

  # The parameters to adjust based off of the desired transformations to apply in preprocessing
  PARAMS:
    AMOUNT_ONLY: False  # If set to True, the tool exits after querying the database and returning counts.
    FLOW: 'No'  # Yes for flow only, No for no flow, and Mixed for videos and flow.
    FLOW_CROP_WIDTH: 90  # Width to resize to for flow if cropping used.
    USE_BOUNDING_BOX: True # Whether to include bounding boxes in npz files
    SMOOTHING: False  # Optional Median filter applied.
    SMOOTHING_KERNEL_SIZE: 5  # Integer, kernel size of square smoothing kernel filter - MUST be odd.
    SHUFFLE: True # If you want to randomize the videos downloaded.
    RANDOM_SEED: 1 # If SHUFFLE=False, this does nothing. Otherwise, this is the seed for shuffling.
    SLIDING_PROPORTION: 1  # Proportion of sliding clips from database to obtain.
    NO_SLIDING_PROPORTION: 1  # Proportion of absent sliding clips from database to obtain.
    M_MODE_WIDTH: 180 # width of m-mode image
    WINDOW_SECONDS: 3 # Mini-clip length measured in seconds
    IMG_SIZE: [224, 224]  # (Height, Width) of final miniclips.
    BASE_FR: 30  # Base frame rate - videos are downsampled to this.
    DB_TABLE: 'clips_alberta'  # Name of the table in the database from which to pull clips.


  # The paths to save files. After running the preprocess pipeline, the npzs and csvs are usually all that are needed to train.
  # You shouldn't *have* to edit these, as they are stored as relative and not absolute paths.
  PATHS:
    UNMASKED_VIDEOS: '\generalizability\raw_videos\alberta'  # Path to the videos that are downloaded from the dataset and stored without transformation.
    MASKED_VIDEOS: '\generalizability\masked_videos\alberta'  # Path to the videos that result from running the masking tool on UNMASKED_VIDEOS.
    SMOOTHED_VIDEOS: '\results\data\smoothed_videos\'  # Path to the videos that result from applying a median filter to MASKED_VIDEOS (optional).
    FLOW_VIDEOS: 'flow_videos\'   # Path to the optical flow video frames (optional).
    CSVS_OUTPUT: 'generalizability\csvs\alberta'  # Path to any CSVs that are generated / taken from the database.
    NPZ: 'generalizability\npzs\alberta'  # Path to the mini-clip videos.
    FLOW_NPZ: 'flow_npzs\'  # Path to the .npzs containing optical flow mini-clips.
    MASKING_TOOL: '\results\data\auto_masking_deeper.h5'  # Path to the masking tool. Currently only works with the older version!!!

    # EXTRA refers to the first infusion of negative additions, which at the time of writing is kept separate
    # from the main resources from the dataset - this could change at any time. We only sometimes use them.
    EXTRA_UNMASKED_VIDEOS: 'extra_unmasked_videos/'  # Path to extra downloaded videos.
    EXTRA_MASKED_VIDEOS: 'extra_masked_videos/'  # Path to extra masked videos.
    EXTRA_FLOW_VIDEOS: 'extra_flow_videos/'  # Path to extra optical flow video frames.
    EXTRA_SMOOTHED_VIDEOS: 'extra_smoothed_videos/'  # Path to extra filtered (with median filter) videos. Currently not implemented.
    EXTRA_NPZ: 'extra_npzs/'  # Path to resultant extra mini-clips.
    EXTRA_FLOW_NPZ: 'extra_flow_npzs/' # Path to resultant extra flow mini-clips.

# TRAIN encompasses all of the parameters to adjust for training models, which all assume that miniclips are stored and preprocessed
# as desired above. This could use a refactor in the future.
TRAIN:
  EXPERIMENT_TYPE: 'train_single' # choose from [train_single, hparam_search, hparam_cross_val_search, cross_val]
  M_MODE: True  # Choose whether or not to perform the M Mode transformation.
  M_MODE_SLICE_METHOD: 'brightest_vertical_sum_sampled' #'brightest_vertical_sum_sampled'  # 'brightest_vertical_sum_sampled', 'brightest_vertical_sum_box' (needs bounding box), 'brightest_vertical_sum', 'brightest' (for brightest pixel),  'box_middle' (needs bounding box) or 'random'.
  M_MODE_SLICE_SAMPLE: 15 # for 'brightest_vertical_sum_sampled', number of slices to randomly sample (top k brightest sums)
  MIXED_PRECISION: False
  OUTPUT_BIAS: False  # A class imbalance technique - whether or not to bias the model (output head) prior to training.
  PATIENCE: 6  # The number of consecutive epochs with val_loss not improving, after which the model halts training.
  MODEL_DEF: 'efficientnet'  # Check models.py for the current list of possible values (which is also where you would create a custom one).
  SAVE_BEST_ONLY: True  # Whether or not to only save the 'best' model, according to validation loss.

  # Parameters used to determine the train, test and validation splits. TRAIN, VAL and TEST have to sum to 1.
  # Only TEST can have a value of 0.
  SPLITS:
    RANDOM_SEED: 5  # The random seed (integer) used for generating splits. -1 for unseeded.
    TRAIN: 0.9  # Proportion of examples to include in the training set.
    VAL: 0.1  # Proportion of examples to include in the validation set.
    TEST: 0  # Proportion of examples to include in the test set.

  # Parameters for augmentation and model-training specifics.
  PARAMS:
    EPOCHS: 40  # Maximum number of epochs to train the model for.
    BATCH_SIZE: 10  # Integer to set the batch size. If you're running into memory errors, you'll have to lower this. Set this to 1 for GRADCAM.
    SHUFFLE: True  # Boolean, whether to shuffle the training set or not.
    INCREASE: False  # Boolean, whether to oversample the minority class (assumed to be the negative class) or not.
    AUGMENTATION_CHANCE: 0.8  # Probability to augment an incoming batch.

    # Parameters for applying data augmentation
    AUGMENTATION:
      BRIGHTNESS_DELTA: 0.1  # Check https://www.tensorflow.org/api_docs/python/tf/image/random_brightness for this parameter.
      HUE_DELTA: 0.2  # Check https://www.tensorflow.org/api_docs/python/tf/image/random_hue for this parameter.
      CONTRAST_BOUNDS: [ 0.7, 1.0 ]  # Check https://www.tensorflow.org/api_docs/python/tf/image/random_contrast for this parameter.
      SHIFT_LEFTRIGHT_BOUNDS: [ -0.25, 0.25 ]  # Proportion of width to shift by - originally -0.25 to 0.25
      SHIFT_UPDOWN_BOUNDS: [ -0.0, 0.0 ]  # Proportion of height to shift by - No upwards shift since many areas of interest are near the top - originally 0.0 to 0.2
      ROTATE_RANGE: [ -0.1, 0.1 ]  # Range of possible rotation angles (radians)
      SHEAR_RANGE: [ 0.0, 0.1 ]  # Check https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_shear for this parameter.
      ZOOM_RANGE: [ 1.0, 1.5 ]  # Zoom range - DO NOT use lower bound < 1, otherwise might cut out parts of pleural line
      RANDOM_NOISE: [ 0.0, 5.0 ]  # (Mean, std) of the noise sampling distribution, for pixel values in range [0, 255]
      MEDIAN_FILTER_SIZE: 5  # Size of median filter to apply

    # The following are model-specific parameters. To understand exactly what each is doing, please consult models.py.

    # EfficentNet, used for M-mode recon
    EFFICIENTNET:
      LR: 0.000171
      LR_DECAY_VAL: 0.05642  # Learning rate decay
      LR_DECAY_EPOCH: 15 # Epoch to start lr decay
      DROPOUT: 0.2151 # Dropout probability
      BLOCKS_FROZEN: 161 # Number of blocks to freeze - MUST be 0 or positive
      L2_REG: 0.008629 # L2 regularization penalty
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers
      ALPHA: 0.105 # focal loss parameter
      GAMMA: 1.1781 # focal loss parameter
      FC0_NODES: 64 # nodes in dense layer
      BLOCK_CUTOFF: 1 # 0-3, number of blocks to remove from the top
      CLASS_WEIGHTS: True # whether to include class distributions in class_weights argument


    # 2D Xception net, used for M-mode reconstructions - Best performing model thus far
    XCEPTION:
      LR: 0.00001  # Learning rate
      LR_DECAY_VAL: 0.1  # Learning rate decay
      DROPOUT: 0.4  # Dropout probability
      BLOCKS: 12  # Number of blocks to use - Integer, in the range [1, 14]
      BLOCKS_FROZEN: 4  # Number of blocks to freeze - MUST be 0 or positive, and less than or equal to the previous ('BLOCKS')
      L2_REG: 0.01  # L2 regularization penalty
      TRANSFER: True  # Whether to use imagenet weights during initialization
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers
      ALPHA: 0.25 # focal loss parameter
      GAMMA: 2.0 # focal loss parameter

    # (Deprecated) test model
    TEST1:
      LR: 0.000001  # Learning rate
      L2_LAMBDA: 0.001  # L2 regularization penalty

    # (Deprecated) Time distributed Xception feature extractor with LSTM, intended for clip input. Untested, currently too large for practical use.
    XCEPTION_RAW:
      LR: 0.0001  # Learning rate
      DROPOUT: 0.5  # Dropout probability

    # Time distributed VGG feature extractor with LSTM, intended for clip input. Not promising, but untested with pleural line crops.
    VGG16:
      LR: 0.0001  # Learning rate
      LR_DECAY_VAL: 0.1  # Learning rate decay
      DROPOUT: 0.5  # Dropout probability
      BLOCKS: 3  # Number of VGG16 blocks to use - Integer, in the range [1, 5]
      L2_REG: 0.01  # L2 regularization penalty - Not currently implemented for this model
      TRANSFER: False  # Whether to use imagenet weights during initialization
      LAST_FROZEN: 4  # Last layer to freeze (NOT 0-indexed), only if TRANSFER = True - for blocks 1 through 5, use 4, 7, 11, 15, 19
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers

    # 3D CNN based on ResNet-12 block structure, intended for clip input, trained from scratch. Not promising.
    RES3D:
      LR: 0.0001
      DROPOUT: 0.5

    # ResNet50 inflated to 3 dimensions, intended for clip input. Pretty mediocre, not always terrible but not that good.
    INFLATED_RESNET50:
      LR: 0.00001  # Learning rate
      LR_DECAY_VAL: 0.1  # Learning rate decay
      DROPOUT: 0.5  # Dropout probability
      L2_REG: 0.01  # L2 regularization penalty
      TRANSFER: True  # Whether to use imagenet weights during initialization
      LAST_FROZEN: 63  # Last layer to freeze (NOT 0-indexed), only if TRANSFER = True - 40 for end of stage 1, 63 for middle of stage 2, 86 for end of stage 2
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers

    # Two-stream 3D Inception net, intended for clip and optical flow clip input. Little testing done.
    I3D:
      LR: 0.000005  # Learning rate
      LR_DECAY_VAL: 0.1  # Learning rate decay
      DROPOUT: 0.5  # Dropout probability
      L2_REG: 0.01  # L2 regularization penalty
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers

    # Basic vision transformer, trained from scratch, intended for M-mode reconstructions (image inputs). Better than clip-input models, but worse than Xception runs.
    # Transfer learning with pre-trained weights has not been tested, but has a good chance of improving performance.
    VIT:
      LR: 0.0005  # Learning rate
      LR_DECAY_VAL: 0.1  # Learning rate decay
      DROPOUT: 0.5  # Dropout probability
      L2_REG: 0.01  # L2 regularization penalty
      WEIGHT_INITIALIZER: 'he_normal'  # Method to initialize weights for convolutional and FC layers - see https://www.tensorflow.org/api_docs/python/tf/keras/initializers
      PROJECTION_DIM: 64  # Dimensionality of patch embeddings
      NUM_HEADS: 8  # Number of attention heads per multi-head attention layer
      TRANSFORMER_LAYERS: 8  # Number of transformer layers
      LAYER_NORM_EPSILON: 0.000001  # Epsilon for layer normalization layers

    # A dense model which uses the variance across time of the M Mode image. Shows little promise.
    VARIANCE_MMODE_NET: # 2D Xception
      LR: 0.0000001 # Learning Rate

    # A custom 1D CNN which assumes M Mode. Shows little promise.
    ONE_D_CONV:
      LR: 0.000001 # Learning Rate

    # MobileNetV3Small from https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small, assuming M Mode
    MOBILENET_V3_SMALL:
      LR: 0.00001 # Learning Rate

  # Path variables involving the training process
  PATHS:
    CSVS: '/generalizability/csvs_split/alberta'  # Path for CSVs describing the splits of the dataset
    MODEL_OUT: '/results/models/efficientnet/'  # Path where the trained model is saved
    TENSORBOARD: '/generalizability/results/logs/fit/'  # Path where the tensorboard logs are stored
    EXPERIMENTS: '../results/experiments/'


# Hyperparameter search model parameters to tune
HPARAM_SEARCH:
  PATH: '../results/experiments/'
  METRICS: ['specificity', 'recall', 'accuracy', 'auc', 'err']
  N_EVALS: 10
  OBJECTIVE: 'weighted_spec_recall' # can change to another metric from METRICS list
  CROSS_VAL_RUNS: 3 # number of runs for cross validation (for each hparam combination)
  LOAD_CHECKPOINT: False
  CHECKPOINT: 'hparam_search_EFFICIENTNET20220323-133041.pkl'
  XCEPTION:
    LR:
      TYPE: 'float_log'
      RANGE: [0.00001, 0.001]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [0.0, 0.5]
    GAMMA: # focal loss parameter
      TYPE: 'float_uniform'
      RANGE: [0, 5]
    ALPHA: # focal loss parameter
      TYPE: 'float_uniform'
      RANGE: [0.01, 1]
  EFFICIENTNET:
    LR:
      TYPE: 'float_log'
      RANGE: [ 0.00001, 0.01 ]
    DROPOUT:
      TYPE: 'float_uniform'
      RANGE: [ 0.2, 0.5 ]
    LR_DECAY_VAL:
      TYPE: 'float_uniform'
      RANGE: [0.01, 0.3]
    GAMMA: # focal loss parameter
      TYPE: 'float_uniform'
      RANGE: [0, 5]
    ALPHA: # focal loss parameter
      TYPE: 'float_uniform'
      RANGE: [0.05, 0.4]
    L2_REG:
      TYPE: 'float_log'
      RANGE: [0.000001, 0.01]
    BLOCK_CUTOFF:
      TYPE: 'set'
      RANGE: [0, 1, 2, 3]
    CLASS_WEIGHTS:
      TYPE: 'set'
      RANGE: [True, False]

CROSS_VAL:
  PARTITIONS: 'data/partitions/'
  N_FOLDS: 10
  METRICS: ['accuracy', 'auc', 'precision', 'recall', 'specificity', 'true_positives', 'true_negatives',
            'false_positives', 'false_negatives'] # metrics to store in output csv

PREDICT:
  MODEL: 'results/models/efficientnet/20220325-190905/'  # Trained model used to generate predictions
  TEST_DF: 'csvs_split/test.csv' # table of NPZs to generate predictions for
  PREDICTIONS_OUT: '../results/predictions'

# EXPLAINABILITY encompasses the parameters needed to produce heatmaps, currently only for convolution-based networks.
EXPLAINABILITY:
  SINGLE_MMODE: True # Set as False to run GradCam for all npzs in NPZ_DF specified below

  # Path variables required for heatmap generation
  PATHS:
    NPZ: 'data/npzs/'  # Directory holding NPZs that heatmaps can be generated for.
    NPZ_DF: 'csvs_split/test.csv'  # Table of mini-clips that heatmaps can be generated for.
    MODEL: 'results/models/efficientnet/20220325-190905'  # Trained model used to generate heatmaps.
    FEATURE_HEATMAPS: 'feature_heatmaps/'  # Output directory for heatmap videos.

EXTERNAL_VAL:
  LOCATIONS: ['chile', 'ottawa', 'alberta']  # List of centers involved in the multi-center study.
  REFRESH_FOLDERS: True  # If you want to delete contents of generalizability-related folders before writing, set True.
  NUM_TRIALS: 5  # Specify the number of fine-tuning trials.
  MIN_TEST_SIZE: 0.5  # Specify the minimum proportion of external data to set aside for testing purposes.
  PARAMS:
    OVERWRITE_FOLDS: True  # Set this to True if you want to overwrite existing fold .txt files.
  PATHS:
    NPZS: '\generalizability\npzs'
    MMODES: '\generalizability\mmodes'  # Path to external data M-mode images.
    CSV_OUT: '\generalizability\csvs'  # Path to external data csvs.
    MODEL_OUT: '\generalizability\results\models'  # Path to fine-tuned models.
    FOLDS: '\generalizability\folds'  # Path to external data patient-wise fold .txt files.
    CSVS_SPLIT: '\generalizability\csvs_split'  # Path to train-test-val splits for external data.
    PREDICTIONS_OUT: '\generalizability\predictions'  # Path to predictions from fine-tuning experiments.
    EXPERIMENTS: '\generalizability\results\experiments'
    TRIALS: '\generalizability\results\experiments\trials'
    PLOTS: '\generalizability\results\experiments\plots'
  FOLD_SAMPLE:
    SEED: 42069  # Seed numbers for sampling external patient ids into slices, which are used during fine-tuning to augment training data as necessary.
    # There is one seed for each trial; insert or remove (or change) seeds as necessary/desired.
    OVERWRITE_FOLDER: True  # Set this to True if you want to overwrite existing fold .txt files.
    NUM_FOLDS: 5  # Number of desired external patient slices for augmenting training data during fine-tuning.
  FINETUNE:
    MODEL_DEF: 'efficientnet'  # Set this equal to the model definition string used for the pre-trained model.
    OVERWRITE_MODEL_DIR: True  # Set True if you want to clear existing contents in the model folder.
    METRIC_THRESHOLDS:  # Thresholds for assessing the performance of a fine-tuned model.
      LOWER_BOUNDS:
        SENSITIVITY: 90.1
        SPECIFICITY: 79.3
      UPPER_BOUNDS:
    MIN_DELTA: 0.0001
    VAL_SPLIT: 0.1 # Specify the train-val data split for each fine-tune run.
    EPOCHS: 100
    PRED_PROBS:
      SAVE_PRED_PROBABILITIES: True # Set to True to save prediction labels for each clip when evaluating fine-tuned models.
    LAZY: False # Set this to True if you want fine-tuning trials to terminate once model performance exceeds thresholds.
    LR: 0.0000171  # For now, divide the original (efficientnet) lr by 10.
    # A value of False will run trials to completion, regardless of whether the model performance exceeds thresholds or not.
  PLOT_METRICS: ['loss', 'sensitivity', 'specificity']  # Specify metrics for which to generate plots (for each trial and trial-wise average).